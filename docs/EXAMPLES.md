# WebAuto æµè§ˆå™¨æ¨¡å— - ä½¿ç”¨ç¤ºä¾‹

## ğŸ“– ç›®å½•

- [1. åŸºç¡€ç¤ºä¾‹](#1-åŸºç¡€ç¤ºä¾‹)
- [2. è¿›é˜¶ç¤ºä¾‹](#2-è¿›é˜¶ç¤ºä¾‹)
- [3. å®æˆ˜é¡¹ç›®](#3-å®æˆ˜é¡¹ç›®)
- [4. æœ€ä½³å®è·µ](#4-æœ€ä½³å®è·µ)

## 1. åŸºç¡€ç¤ºä¾‹

### 1.1 å¿«é€Ÿå¼€å§‹

```python
from browser_interface import quick_test

# ä¸€è¡Œä»£ç æµ‹è¯•ç™¾åº¦
quick_test()

# è‡ªå®šä¹‰æµ‹è¯•
quick_test(url='https://weibo.com', wait_time=3)
```

### 1.2 åŸºç¡€æµè§ˆå™¨æ“ä½œ

```python
from browser_interface import create_browser
def basic_browsing():
    """åŸºç¡€æµè§ˆå™¨æ“ä½œ"""
    with create_browser() as browser:
        # è®¿é—®ç™¾åº¦
        page = browser.goto('https://www.baidu.com')
        print(f'é¡µé¢æ ‡é¢˜: {page.title()}')
        
        # å¡«å†™æœç´¢æ¡†
        page.fill('#kw', 'Python è‡ªåŠ¨åŒ–')
        
        # ç‚¹å‡»æœç´¢æŒ‰é’®
        page.click('#su')
        
        # ç­‰å¾…ç»“æœ
        import time
        time.sleep(2)
        
        print(f'æœç´¢ç»“æœ: {page.title()}')

basic_browsing()
```

### 1.3 å¤šé¡µé¢æ“ä½œ

```python
from browser_interface import create_browser
def multi_page_operations():
    """å¤šé¡µé¢æ“ä½œ"""
    with create_browser() as browser:
        # é¡µé¢1 - ç™¾åº¦
        page1 = browser.goto('https://www.baidu.com')
        page1.fill('#kw', 'Python')
        
        # é¡µé¢2 - å¾®åš
        page2 = browser.goto('https://weibo.com')
        print(f'å¾®åšæ ‡é¢˜: {page2.title()}')
        
        # é¡µé¢3 - çŸ¥ä¹
        page3 = browser.goto('https://www.zhihu.com')
        print(f'çŸ¥ä¹æ ‡é¢˜: {page3.title()}')
        
        # å›åˆ°é¡µé¢1å¹¶æœç´¢
        page1.click('#su')
        print(f'æœç´¢å®Œæˆ: {page1.title()}')

multi_page_operations()
```

## 2. è¿›é˜¶ç¤ºä¾‹

### 2.1 éšåŒ¿æ¨¡å¼çˆ¬å–

```python
from browser_interface import stealth_mode
import time
import json

def stealth_scraping(url):
    """éšåŒ¿æ¨¡å¼çˆ¬å–"""
    with stealth_mode() as browser:
        page = browser.goto(url)
        
        # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
        page.mouse.move(100, 100)
        time.sleep(1)
        
        page.evaluate('window.scrollBy(0, 200)')
        time.sleep(1)
        
        # è·å–é¡µé¢ä¿¡æ¯
        info = {
            'title': page.title(),
            'url': page.url(),
            'user_agent': page.evaluate('navigator.userAgent'),
            'has_webdriver': page.evaluate('navigator.webdriver !== undefined'),
            'timestamp': time.time()
        }
        
        return info

# ä½¿ç”¨
result = stealth_scraping('https://bot.sannysoft.com')
print(f'éšåŒ¿æ¨¡å¼ç»“æœ: {result}')
```

### 2.2 æ— å¤´æ¨¡å¼æ‰¹é‡å¤„ç†

```python
from browser_interface import headless_mode
def batch_processing(urls):
    """æ‰¹é‡å¤„ç†å¤šä¸ªURL"""
    results = []
    
    with headless_mode() as browser:
        for i, url in enumerate(urls, 1):
            try:
                page = browser.goto(url)
                
                result = {
                    'index': i,
                    'url': url,
                    'title': page.title(),
                    'success': True
                }
                
                print(f'{i}. {url} - {page.title()}')
                
            except Exception as e:
                result = {
                    'index': i,
                    'url': url,
                    'error': str(e),
                    'success': False
                }
                
                print(f'{i}. {url} - å¤±è´¥: {e}')
            
            results.append(result)
    
    return results

# ä½¿ç”¨
sites = [
    'https://www.baidu.com',
    'https://weibo.com',
    'https://www.zhihu.com'
]

results = batch_processing(sites)
successful = len([r for r in results if r['success']])
print(f'æˆåŠŸå¤„ç†: {successful}/{len(sites)} ä¸ªç½‘ç«™')
```

### 2.3 è‡ªå®šä¹‰é…ç½®ä½¿ç”¨

```python
from browser_interface import create_browser
def custom_config_example():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹"""
    # è‡ªå®šä¹‰é…ç½®
    config = {
        'headless': False,
        'locale': 'zh-CN',
        'args': [
            '--lang=zh-CN',
            '--window-size=1920,1080',
            '--disable-gpu',
            '--no-sandbox',
            '--force-charset=UTF-8'
        ]
    }
    
    with create_browser(config=config) as browser:
        page = browser.goto('https://www.baidu.com')
        
        # æ£€æŸ¥é…ç½®æ•ˆæœ
        info = page.evaluate('{'
            user_agent: navigator.userAgent,
            language: navigator.language,
            charset: document.characterSet
        }')
        
        print(f'é¡µé¢æ ‡é¢˜: {page.title()}')
        print(f'æµè§ˆå™¨ä¿¡æ¯: {info}')
        
        # æˆªå›¾
        page.screenshot('custom_config_test.png', full_page=True)

custom_config_example()
```

## 3. å®æˆ˜é¡¹ç›®

### 3.1 ç™¾åº¦æœç´¢çˆ¬è™«

```python
from browser_interface import create_browser
import time
import json

class BaiduSpider:
    """ç™¾åº¦æœç´¢çˆ¬è™«"""
    
    def __init__(self):
        self.results = []
    
    def search(self, keyword, max_pages=3):
        """æœç´¢å…³é”®è¯"""
        with create_browser() as browser:
            page = browser.goto('https://www.baidu.com')
            
            # å¡«å†™æœç´¢æ¡†
            page.fill('#kw', keyword)
            page.click('#su')
            
            # ç­‰å¾…æœç´¢ç»“æœ
            time.sleep(2)
            
            # çˆ¬å–å¤šé¡µç»“æœ
            for page_num in range(max_pages):
                try:
                    self._extract_results(page, page_num + 1)
                    
                    if page_num < max_pages - 1:
                        # ç‚¹å‡»ä¸‹ä¸€é¡µ
                        page.click('.n:contains("ä¸‹ä¸€é¡µ")')
                        time.sleep(2)
                        
                except Exception as e:
                    print(f'ç¬¬{page_num + 1}é¡µæå–å¤±è´¥: {e}')
                    break
        
        return self.results
    
    def _extract_results(self, page, page_num):
        """æå–æœç´¢ç»“æœ"""
        try:
            # è·å–æ‰€æœ‰ç»“æœé¡¹
            results = page.query_selector_all('.result')
            
            for i, result in enumerate(results):
                try:
                    title_elem = result.query_selector('h3 a')
                    if title_elem:
                        title = title_elem.text_content()
                        href = title_elem.get_attribute('href')
                        
                        # è·å–æ‘˜è¦
                        summary_elem = result.query_selector('.c-abstract')
                        summary = summary_elem.text_content() if summary_elem else ''
                        
                        self.results.append({
                            'page': page_num,
                            'position': i + 1,
                            'title': title.strip(),
                            'url': href,
                            'summary': summary.strip()
                        })
                        
                except Exception as e:
                    print(f'æå–ç¬¬{i+1}ä¸ªç»“æœå¤±è´¥: {e}')
                    continue
        
        except Exception as e:
            print(f'é¡µé¢{page_num}ç»“æœæå–å¤±è´¥: {e}')
    
    def save_results(self, filename='baidu_search_results.json'):
        """ä¿å­˜ç»“æœ"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        print(f'ç»“æœå·²ä¿å­˜åˆ°: {filename}')

# ä½¿ç”¨ç¤ºä¾‹
spider = BaiduSpider()
results = spider.search('Python è‡ªåŠ¨åŒ–', max_pages=2)
spider.save_results()

print(f'æ€»å…±æå–åˆ° {len(results)} ä¸ªæœç´¢ç»“æœ')
```

### 3.2 ç½‘ç«™ä¿¡æ¯é‡‡é›†å™¨

```python
from browser_interface import create_browser, stealth_mode
import time
import json
from datetime import datetime

class WebsiteInfoCollector:
    """ç½‘ç«™ä¿¡æ¯é‡‡é›†å™¨"""
    
    def __init__(self, use_stealth=False):
        self.use_stealth = use_stealth
    
    def collect_single(self, url):
        """é‡‡é›†å•ä¸ªç½‘ç«™ä¿¡æ¯"""
        try:
            if self.use_stealth:
                browser_creator = stealth_mode
            else:
                browser_creator = create_browser
            
            with browser_creator() as browser:
                page = browser.goto(url)
                
                # åŸºç¡€ä¿¡æ¯
                info = {
                    'url': url,
                    'title': page.title(),
                    'final_url': page.url(),
                    'timestamp': datetime.now().isoformat(),
                    'success': True
                }
                
                # æŠ€æœ¯ä¿¡æ¯
                tech_info = page.evaluate('{'
                    language: document.documentElement.lang,
                    charset: document.characterSet,
                    viewport: {
                        width: window.innerWidth,
                        height: window.innerHeight
                    },
                    user_agent: navigator.userAgent
                }')
                info.update(tech_info)
                
                # SEO ä¿¡æ¯
                try:
                    description = page.text_content('meta[name="description"]')
                    keywords = page.text_content('meta[name="keywords"]')
                    
                    if description:
                        info['description'] = description.strip()
                    if keywords:
                        info['keywords'] = keywords.strip()
                except:
                    pass
                
                # æˆªå›¾
                screenshot_name = f'{url.replace("https://", "").replace("/", "_")}.png'
                page.screenshot(screenshot_name)
                info['screenshot'] = screenshot_name
                
                return info
                
        except Exception as e:
            return {
                'url': url,
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def collect_batch(self, urls, delay=2):
        """æ‰¹é‡é‡‡é›†ç½‘ç«™ä¿¡æ¯"""
        results = []
        
        for i, url in enumerate(urls, 1):
            print(f'é‡‡é›† {i}/{len(urls)}: {url}')
            
            result = self.collect_single(url)
            results.append(result)
            
            if i < len(urls):
                print(f'ç­‰å¾… {delay} ç§’...')
                time.sleep(delay)
        
        return results
    
    def generate_report(self, results, filename='website_report.html'):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        html = '<html><head><meta charset="UTF-8"><title>ç½‘ç«™ä¿¡æ¯æŠ¥å‘Š</title></head><body>'
        html += '<h1>ç½‘ç«™ä¿¡æ¯é‡‡é›†æŠ¥å‘Š</h1>'
        html += f'<p>é‡‡é›†æ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>'
        html += f'<p>æ€»è®¡: {len(results)} ä¸ªç½‘ç«™</p>'
        html += '<table border="1" style="border-collapse: collapse; width: 100%;">'
        html += '<tr><th>URL</th><th>æ ‡é¢˜</th><th>è¯­è¨€</th><th>çŠ¶æ€</th></tr>'
        
        for result in results:
            status = 'æˆåŠŸ' if result['success'] else 'å¤±è´¥'
            title = result.get('title', 'æœªçŸ¥')
            language = result.get('language', 'æœªçŸ¥')
            url = result['url']
            
            html += f'<tr><td>{url}</td><td>{title}</td><td>{language}</td><td>{status}</td></tr>'
        
        html += '</table></body></html>'
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f'æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}')

# ä½¿ç”¨ç¤ºä¾‹
collector = WebsiteInfoCollector(use_stealth=True)

sites = [
    'https://www.baidu.com',
    'https://weibo.com',
    'https://www.zhihu.com',
    'https://github.com'
]

# é‡‡é›†ä¿¡æ¯
results = collector.collect_batch(sites, delay=2)

# ç”ŸæˆæŠ¥å‘Š
collector.generate_report(results)

# ä¿å­˜JSONæ•°æ®
with open('website_data.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f'é‡‡é›†å®Œæˆï¼ŒæˆåŠŸ: {len([r for r in results if r["success"]])}/{len(sites)}')
```

### 3.3 ä»·æ ¼ç›‘æ§å·¥å…·

```python
from browser_interface import headless_mode
import time
import json
from datetime import datetime

class PriceMonitor:
    """ä»·æ ¼ç›‘æ§å·¥å…·"""
    
    def __init__(self, config_file='price_config.json'):
        self.config_file = config_file
        self.load_config()
    
    def load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        except FileNotFoundError:
            # åˆ›å»ºé»˜è®¤é…ç½®
            self.config = {
                'products': [
                    {
                        'name': 'ç¤ºä¾‹å•†å“',
                        'url': 'https://example.com/product/1',
                        'price_selector': '.price',
                        'name_selector': '.product-name',
                        'target_price': 100.0
                    }
                ],
                'check_interval': 3600,  # 1å°æ—¶
                'notification': {
                    'email': 'your@email.com',
                    'enabled': False
                }
            }
            self.save_config()
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def check_prices(self):
        """æ£€æŸ¥ä»·æ ¼"""
        results = []
        
        with headless_mode() as browser:
            for product in self.config['products']:
                try:
                    result = self._check_single_product(browser, product)
                    results.append(result)
                    
                    if result['price_drop']:
                        self._notify_price_drop(result)
                        
                except Exception as e:
                    results.append({
                        'name': product['name'],
                        'success': False,
                        'error': str(e),
                        'timestamp': datetime.now().isoformat()
                    })
        
        return results
    
    def _check_single_product(self, browser, product):
        """æ£€æŸ¥å•ä¸ªå•†å“ä»·æ ¼"""
        page = browser.goto(product['url'])
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(2)
        
        # è·å–å•†å“åç§°
        name = page.text_content(product['name_selector'])
        
        # è·å–ä»·æ ¼
        price_text = page.text_content(product['price_selector'])
        price = self._extract_price(price_text)
        
        # æ£€æŸ¥ä»·æ ¼å˜åŒ–
        target_price = product['target_price']
        price_drop = price and price <= target_price
        
        return {
            'name': name,
            'url': product['url'],
            'price': price,
            'price_text': price_text,
            'target_price': target_price,
            'price_drop': price_drop,
            'success': True,
            'timestamp': datetime.now().isoformat()
        }
    
    def _extract_price(self, price_text):
        """ä»ä»·æ ¼æ–‡æœ¬ä¸­æå–æ•°å€¼"""
        if not price_text:
            return None
        
        import re
        
        # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼Œä¿ç•™å°æ•°ç‚¹
        price_clean = re.sub(r'[^0-9.]', '', price_text)
        
        try:
            return float(price_clean)
        except ValueError:
            return None
    
    def _notify_price_drop(self, result):
        """é€šçŸ¥ä»·æ ¼ä¸‹é™"""
        message = f"ä»·æ ¼ä¸‹é™é€šçŸ¥: {result['name']}\n"
        message += f"å½“å‰ä»·æ ¼: {result['price']}\n"
        message += f"ç›®æ ‡ä»·æ ¼: {result['target_price']}\n"
        message += f"å•†å“é“¾æ¥: {result['url']}"
        
        print(f"ğŸ”” ä»·æ ¼ä¸‹é™é€šçŸ¥:\n{message}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ é‚®ä»¶é€šçŸ¥ç­‰
        if self.config['notification']['enabled']:
            # send_email_notification(message)
            pass
    
    def run_monitor(self, run_once=False):
        """è¿è¡Œç›‘æ§"""
        print(f"ä»·æ ¼ç›‘æ§å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {self.config['check_interval']}ç§’")
        
        while True:
            print(f"å¼€å§‹æ£€æŸ¥ä»·æ ¼... {datetime.now()}")
            
            results = self.check_prices()
            
            # ä¿å­˜æ£€æŸ¥ç»“æœ
            with open('price_check_log.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ä»·æ ¼æ£€æŸ¥å®Œæˆï¼Œæ£€æŸ¥äº† {len(results)} ä¸ªå•†å“")
            
            if run_once:
                break
            
            print(f"ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {datetime.fromtimestamp(time.time() + self.config['check_interval'])}")
            time.sleep(self.config['check_interval'])

# ä½¿ç”¨ç¤ºä¾‹
monitor = PriceMonitor()

# è¿è¡Œä¸€æ¬¡æµ‹è¯•
monitor.run_monitor(run_once=True)

# æŒç»­ç›‘æ§
# monitor.run_monitor()
```

## 4. æœ€ä½³å®è·µ

### 4.1 èµ„æºç®¡ç†

```python
from browser_interface import create_browser

def resource_management_example():
    """èµ„æºç®¡ç†æœ€ä½³å®è·µ"""
    
    # âœ… æ¨èï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with create_browser() as browser:
        page = browser.goto('https://www.baidu.com')
        # æµè§ˆå™¨è‡ªåŠ¨å…³é—­
    
    # âŒ ä¸æ¨èï¼šæ‰‹åŠ¨ç®¡ç†
    browser = create_browser()
    try:
        page = browser.new_page()
        page.goto('https://www.baidu.com')
    finally:
        browser.close()  # å®¹æ˜“å¿˜è®°
```

### 4.2 é”™è¯¯å¤„ç†

```python
from browser_interface import create_browser, SecurityError
import logging

def error_handling_example():
    """é”™è¯¯å¤„ç†æœ€ä½³å®è·µ"""
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    try:
        with create_browser() as browser:
            page = browser.goto('https://www.baidu.com')
            logger.info(f'é¡µé¢åŠ è½½æˆåŠŸ: {page.title()}')
            
    except SecurityError as e:
        logger.error(f'å®‰å…¨é”™è¯¯: {e}')
        # åªèƒ½ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥æ–¹å¼
        
    except Exception as e:
        logger.error(f'æ“ä½œå¤±è´¥: {e}')
        # å…¶ä»–é”™è¯¯å¤„ç†
```

### 4.3 æ€§èƒ½ä¼˜åŒ–

```python
from browser_interface import headless_mode
import time

def performance_optimization_example():
    """æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ"""
    
    # æ‰¹é‡å¤„ç†ï¼Œå¤ç”¨æµè§ˆå™¨å®ä¾‹
    urls = ['https://www.baidu.com', 'https://weibo.com', 'https://www.zhihu.com']
    
    with headless_mode() as browser:  # æ— å¤´æ¨¡å¼æå‡æ€§èƒ½
        for url in urls:
            try:
                page = browser.goto(url)
                print(f'å¤„ç†å®Œæˆ: {url} - {page.title()}')
                
                # åŠæ—¶é‡Šæ”¾é¡µé¢èµ„æº
                # page.close()  # å¦‚æœéœ€è¦
                
            except Exception as e:
                print(f'å¤„ç†å¤±è´¥: {url} - {e}')
                continue
```

### 4.4 é…ç½®ç®¡ç†

```python
from browser_interface import create_browser, get_stealth_config, get_headless_config

def configuration_management_example():
    """é…ç½®ç®¡ç†æœ€ä½³å®è·µ"""
    
    # ä½¿ç”¨å†…ç½®é…ç½®
    stealth_config = get_stealth_config()
    headless_config = get_headless_config()
    
    print(f'éšåŒ¿é…ç½®å‚æ•°: {len(stealth_config["args"])}ä¸ª')
    print(f'æ— å¤´æ¨¡å¼: {headless_config["headless"]}')
    
    # è‡ªå®šä¹‰é…ç½®
    custom_config = {
        'headless': False,
        'locale': 'zh-CN',
        'args': [
            '--lang=zh-CN',
            '--window-size=1920,1080',
            '--disable-gpu'
        ]
    }
    
    with create_browser(config=custom_config) as browser:
        page = browser.goto('https://www.baidu.com')
        print(f'è‡ªå®šä¹‰é…ç½®æµ‹è¯•: {page.title()}')
```

---

## æ€»ç»“

é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- âœ… æŒæ¡åŸºç¡€çš„æµè§ˆå™¨æ“ä½œ
- âœ… å®ç°å¤æ‚çš„çˆ¬å–ä»»åŠ¡
- âœ… å¼€å‘å®ç”¨çš„ç›‘æ§å·¥å…·
- âœ… éµå¾ªæœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–

**å¼€å§‹ä½ çš„ç¬¬ä¸€ä¸ª WebAuto é¡¹ç›®å§ï¼**

## ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå…¥é—¨æŒ‡å—](QUICK_START.md) - 5åˆ†é’Ÿä¸Šæ‰‹
- [ç”¨æˆ·æŒ‡å—](USER_GUIDE.md) - è¯¦ç»†ä½¿ç”¨è¯´æ˜
- [API å‚è€ƒæ–‡æ¡£](API_REFERENCE.md) - å®Œæ•´APIæ–‡æ¡£
- [æ¶æ„è®¾è®¡æ–‡æ¡£](ARCHITECTURE.md) - ç†è§£æŠ½è±¡å±‚è®¾è®¡
- [æ•…éšœæ’é™¤æŒ‡å—](TROUBLESHOOTING.md) - å¸¸è§é—®é¢˜è§£å†³

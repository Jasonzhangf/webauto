#!/usr/bin/env python3
"""
ä¸‹è½½UI-Ins-32Bæ¨¡å‹è„šæœ¬
"""

import os
from pathlib import Path
import subprocess
import sys

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    try:
        import torch
        from huggingface_hub import snapshot_download
        print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…: pip install torch huggingface_hub")
        return False

def download_ui_ins_32b():
    """ä¸‹è½½UI-Ins-32Bæ¨¡å‹"""
    model_name = "Qwen/UI-Ins-32B"
    local_path = "./models/ui-ins-32b"

    # è®¾ç½®é•œåƒ
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

    print(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"ä¿å­˜è·¯å¾„: {local_path}")
    print("âš ï¸  32Bæ¨¡å‹è¾ƒå¤§ï¼Œé¢„è®¡éœ€è¦20GB+å­˜å‚¨ç©ºé—´")

    try:
        from huggingface_hub import snapshot_download

        # ä¸‹è½½æ¨¡å‹
        snapshot_download(
            repo_id=model_name,
            local_dir=local_path,
            local_dir_use_symlinks=False,
            token=os.getenv('HF_TOKEN', None)  # å¦‚æœéœ€è¦token
        )

        print("âœ… UI-Ins-32Bæ¨¡å‹ä¸‹è½½å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        return False

def cleanup_unwanted_models():
    """æ¸…ç†ä¸éœ€è¦çš„æ¨¡å‹"""
    models_dir = Path("./models")

    # éœ€è¦ä¿ç•™çš„æ¨¡å‹
    keep_models = ["ui-ins-7b", "ui-ins-32b"]

    print("ğŸ§¹ æ¸…ç†ä¸éœ€è¦çš„æ¨¡å‹...")

    for model_dir in models_dir.iterdir():
        if model_dir.is_dir() and model_dir.name not in keep_models:
            print(f"åˆ é™¤æ¨¡å‹: {model_dir.name}")
            import shutil
            shutil.rmtree(model_dir)
            print(f"âœ… å·²åˆ é™¤: {model_dir.name}")

def check_disk_space():
    """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
    import shutil
    total, used, free = shutil.disk_usage("./")
    free_gb = free // (1024**3)

    print(f"å¯ç”¨ç£ç›˜ç©ºé—´: {free_gb}GB")

    if free_gb < 25:
        print("âš ï¸  ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®è‡³å°‘25GBå¯ç”¨ç©ºé—´")
        return False

    return True

def main():
    print("ğŸ¤– UI-Ins-32Bæ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)

    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    if not check_disk_space():
        print("ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œé€€å‡º")
        return

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return

    # è¯¢é—®æ˜¯å¦ç»§ç»­
    response = input("æ˜¯å¦ç»§ç»­ä¸‹è½½UI-Ins-32Bæ¨¡å‹ï¼Ÿ(y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("å–æ¶ˆä¸‹è½½")
        return

    # ä¸‹è½½æ¨¡å‹
    if download_ui_ins_32b():
        # æ¸…ç†ä¸éœ€è¦çš„æ¨¡å‹
        cleanup_response = input("æ˜¯å¦æ¸…ç†ä¸éœ€è¦çš„æ¨¡å‹ï¼Ÿ(y/N): ")
        if cleanup_response.lower() in ['y', 'yes']:
            cleanup_unwanted_models()

        print("ğŸ‰ æ¨¡å‹é…ç½®å®Œæˆ")
    else:
        print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")

if __name__ == "__main__":
    main()